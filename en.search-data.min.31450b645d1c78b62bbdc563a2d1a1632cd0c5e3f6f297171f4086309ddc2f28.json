[{"id":0,"href":"/Lynx/docs/usage/installation/","title":"Installation \u0026 Setup","section":"Introduction","content":"Installation and Setup Guide# This guide covers everything you need to get Lynx FIM running on your system, from compiling the source code to ensuring it stays running after a reboot.\n1. Supported Platforms# Lynx FIM is built in Go and leverages the Linux kernel\u0026rsquo;s inotify system for real-time monitoring.\nPrimary Support: Linux (Ubuntu, Debian, CentOS, RHEL, etc.). Architecture: AMD64 and ARM64. Other OS: While it will compile on macOS or Windows, the real-time recursive monitoring features are optimized for Linux. 2. Build and Installation# Prerequisites# Go 1.22+: Required to compile the source. Make: Recommended for using the automated build script. Compilation Steps# Clone the repository: git clone https://github.com/ItsAdam01/Lynx.git cd Lynx Build for your current architecture: make build (Optional) Install to your path: sudo cp bin/lynx /usr/local/bin/ 3. Configuration Setup# Step 1: Initialize# Generate a default configuration file in your current directory:\nlynx initStep 2: The HMAC Secret# Lynx requires a secret key to protect the integrity of its baseline. You must set this as an environment variable. I learned that keeping secrets out of config files is a major security best practice.\nGenerating a Secure Secret# To generate a cryptographically secure random string for your secret, I recommend using OpenSSL:\n# Generate a random 32-byte base64 encoded string openssl rand -base64 32Once you have your secret, export it to your environment:\nexport LYNX_HMAC_SECRET=\u0026#34;your-generated-output-here\u0026#34;Step 3: Configure config.yaml# Open the generated config.yaml. Here is a sample of how I configured mine:\nagent_name: \u0026#34;prod-web-server-01\u0026#34; hmac_secret_env: \u0026#34;LYNX_HMAC_SECRET\u0026#34; # The NAME of the env var, not the secret! log_file: \u0026#34;/var/log/lynx.log\u0026#34; webhook_url: \u0026#34;https://discord.com/api/webhooks/...\u0026#34; # Your Discord Webhook # Directories to monitor recursively paths_to_watch: - \u0026#34;/etc/ssh\u0026#34; - \u0026#34;/etc/pam.d\u0026#34; - \u0026#34;/usr/local/bin\u0026#34; # Specific critical files files_to_watch: - \u0026#34;/etc/passwd\u0026#34; - \u0026#34;/etc/shadow\u0026#34; - \u0026#34;/etc/hosts\u0026#34;4. Running the Agent# Permissions# Because Lynx needs to read sensitive system files (like /etc/shadow) and hook into kernel events, it must be run with root privileges.\nsudo LYNX_HMAC_SECRET=\u0026#34;your-secret\u0026#34; ./bin/lynx start5. Persistence (Running as a Service)# To ensure Lynx FIM starts automatically when the server boots and restarts if it fails, you should use systemd. This is how professional HIDS agents are deployed.\nStep 1: Create the Service File# Create a file at /etc/systemd/system/lynx.service:\n[Unit] Description=Lynx File Integrity Monitor After=network.target [Service] Type=simple User=root WorkingDirectory=/opt/lynx # Pass the secret via environment variable Environment=LYNX_HMAC_SECRET=your-super-long-secret-key ExecStart=/usr/local/bin/lynx start --config /opt/lynx/config.yaml Restart=always RestartSec=5 [Install] WantedBy=multi-user.targetStep 2: Enable and Start# Run the following commands to activate the service:\n# Reload systemd to recognize the new service sudo systemctl daemon-reload # Enable the service to start on boot sudo systemctl enable lynx # Start the service immediately sudo systemctl start lynx # Check the status sudo systemctl status lynx6. Directory Recommendations# ‚úÖ Recommended to Watch# /etc/: System configuration files. /usr/bin/ or /usr/local/bin/: System executables. /root/.ssh/: Unauthorized SSH keys. ‚ùå Not Recommended to Watch# /proc/ or /sys/: Virtual kernel file systems. /var/log/: High-frequency log writes. /tmp/: High-noise temporary storage. üó∫Ô∏è Navigation# Command Reference: How to operate the agent. General Features: What Lynx can do for you. Back to Introduction "},{"id":1,"href":"/Lynx/docs/","title":"Introduction","section":"Lynx FIM","content":"Lynx FIM Documentation# Welcome to the documentation for Lynx FIM, a lightweight host-based intrusion detection agent built in Go. This site is organized into two primary sections to help you navigate the project.\nüó∫Ô∏è How to Use These Docs# üöÄ Usage Guide# If you want to run Lynx FIM on your system, start here. This section covers:\nInstallation \u0026amp; Setup: How to build the agent and configure it. Command Reference: Detailed syntax for all CLI commands. Isolated Lab Testing: Guide for safe, single-directory testing. üíª Development \u0026amp; Research# If you\u0026rsquo;re interested in the \u0026ldquo;how\u0026rdquo; and \u0026ldquo;why\u0026rdquo; behind the tool, explore this section:\nTechnical Specifications: My research into Go, Cryptography, and Kernel events. Implementation Story: A milestone-by-milestone log of my learning journey. Performance Analysis: Benchmarking results and throughput research. Implementation Plan: The original roadmap for Summer 2025. Requirements: What I defined as essential for a modern FIM. Note: This project is part of a 2-month intensive learning cycle from June to August 2025. I\u0026rsquo;m building this from scratch to truly understand the core concepts of system security.\n"},{"id":2,"href":"/Lynx/docs/usage/features/","title":"General Features","section":"Introduction","content":"Lynx FIM: Complete Feature Guide# Lynx FIM is a focused, high-performance host-based intrusion detection agent. This page provides a comprehensive breakdown of every feature I\u0026rsquo;ve implemented during this project.\n1. Cryptographic Integrity (The Baseline)# Lynx relies on a \u0026ldquo;Source of Truth\u0026rdquo;: a cryptographic record of every file you choose to protect.\nSHA-256 Hashing: Every monitored file is fingerprinted using the industry-standard SHA-256 algorithm. Even a single bit change in a file will result in a completely different hash. HMAC Protection: The baseline.json file is signed with a Hash-based Message Authentication Code (HMAC). This ensures that even if an attacker modifies the baseline file, the agent will detect the tampering and refuse to trust it. Configuration Locking: Lynx hashes your config.yaml and stores that hash in the baseline. This prevents unauthorized changes to your watch paths or ignore lists after the baseline has been established. Tamper Alerting: If Lynx detects that its baseline.json or config.yaml has been tampered with during startup, it will send a critical webhook notification before exiting. This ensures the security team is aware that the agent\u0026rsquo;s integrity has been compromised. 2. Real-time Monitoring# Lynx doesn\u0026rsquo;t just scan files; it actively defends your system using kernel-level event hooks.\nfsnotify Integration: Leverages the Linux inotify system to receive instant notifications from the kernel whenever a file is touched. Event Detection: Specifically monitors for: Creation: New files appearing in watched directories. Modification: Changes to the content of existing monitored files. Deletion: Monitored files being removed. Renaming: Automatically detected and reported as a deletion of the original path. Recursive Watching: When you watch a directory, Lynx automatically monitors every subdirectory within it. If you create a new folder, Lynx hooks into it immediately without requiring a restart. 3. Advanced Filtering \u0026amp; Noise Reduction# To be useful in production, a FIM must be quiet. I\u0026rsquo;ve implemented a robust \u0026ldquo;ignore\u0026rdquo; mechanism to reduce alert fatigue.\nIgnore Patterns: Support for .gitignore-style patterns in your configuration. You can exclude noisy files (like *.log, *.tmp, or .DS_Store) using standard shell globbing. Global \u0026amp; Local Paths: Ignore rules apply recursively to all monitored directories. 4. Professional Alerting Pipeline# Detecting a breach is only half the battle; the other half is making sure the right people know about it instantly.\nStructured JSON Logging: Every security event is logged as a machine-readable JSON object. This is perfect for integration with SIEM platforms like Splunk, ELK, or Datadog. Asynchronous Webhooks: Alerts are dispatched to Discord or Slack in the background using a non-blocking queue. This ensures that network latency never slows down the core monitoring loop. Agent Identification: Every alert includes an agent_name (configured in config.yaml). This serves as a unique identifier for the host, allowing security teams to quickly pinpoint which server in a fleet is reporting the incident. Semantic Labeling: Webhook payloads use professional, text-based semantic labels (e.g., [CRITICAL], [WARNING]) instead of excessive icons. This ensures that the output is clean, readable, and focused on the data. 5. Flexible Operation Modes# Lynx is designed to be both a persistent defender and a manual audit tool.\nPersistent Agent (start): A long-running background process with graceful shutdown handling. Manual Audit (verify): A one-off command that performs a comprehensive \u0026ldquo;clean sweep\u0026rdquo; comparison of your entire system against the baseline and prints a detailed report. Easy Scaffolding (init): Instantly generate a boilerplate configuration to get started in seconds. üó∫Ô∏è Navigation# Installation \u0026amp; Setup: How to get started. Command Reference: Detailed syntax. Back to Introduction "},{"id":3,"href":"/Lynx/docs/development/requirements/","title":"Requirements","section":"Introduction","content":"Requirements: Building a Modern FIM# As I research existing host-based intrusion detection systems (HIDS) like OSSEC or Wazuh, I\u0026rsquo;m identifying the core functionality that a modern File Integrity Monitor (FIM) actually needs. For Lynx FIM, I\u0026rsquo;m prioritizing the following requirements for my initial learning build.\nFunctional Requirements# The FIM agent must be able to perform these core tasks:\nBaseline Creation: Recursive Scanning: Scan configured directories (like /etc/, /usr/bin/) and identify all files. Hashing: Generate a SHA-256 cryptographic hash for every file to create its unique \u0026ldquo;fingerprint.\u0026rdquo; Secure Storage: Save the \u0026ldquo;known-good\u0026rdquo; baseline to a file for later comparison. Real-time Monitoring: Event Detection: Listen for kernel-level file events: Create, Write, Delete, and Rename. Anomaly Comparison: When an event occurs, immediately compare the new file state against the baseline to identify the change. Alerting \u0026amp; Logging: Structured Output: Log all events in a machine-readable JSON format for easy parsing and ingestion. Immediate Alerting: Send a POST request to a pre-configured webhook (Slack/Discord) for any high-priority change (e.g., a change to /etc/passwd). Self-Protection: Integrity Verification: The baseline file itself must be signed with an HMAC (Hash-based Message Authentication Code). Tamper Detection: The agent must refuse to start if the baseline\u0026rsquo;s signature doesn\u0026rsquo;t match its current content. Non-Functional Requirements# These are the \u0026ldquo;quality\u0026rdquo; goals I\u0026rsquo;m aiming for as a developer:\nPerformance: The agent must have a minimal CPU and memory footprint. It should watch thousands of files without impacting server performance. Zero Dependencies: By using Go, I want a single, statically linked binary that I can drop onto any Linux server (Ubuntu, CentOS, etc.) and it \u0026ldquo;just works.\u0026rdquo; Security: The HMAC secret key must be handled securely (e.g., via an environment variable) and never hardcoded in the repository. My Learning Goals (Why I\u0026rsquo;m Doing This)# Go Systems Programming: Learn how to build long-running, concurrent services in Go. Linux Security Fundamentals: Understand how the Linux kernel notifies userspace about file changes (inotify). Cryptography Basics: Get hands-on experience with SHA-256 and HMAC to learn how data integrity is actually enforced in the real world. üó∫Ô∏è Navigation# Technical Specifications: How these requirements are built. Implementation Plan: Timeline for the build. Back to Introduction "},{"id":4,"href":"/Lynx/docs/usage/commands/","title":"Command Reference","section":"Introduction","content":"CLI Command Reference# Lynx FIM is operated through a simple but powerful command-line interface. All commands support the global --config flag to specify a custom configuration path.\nGlobal Flags# --config string: Path to the configuration file (default is \u0026ldquo;config.yaml\u0026rdquo;). -h, --help: Display help information for any command. 1. lynx init# Initializes the workspace for Lynx FIM.\nUsage# lynx init [flags]What it does:# Creates a boilerplate config.yaml file in the current directory with sensible defaults. This is always the first step when setting up a new agent.\n2. lynx baseline# Establishes the \u0026ldquo;Source of Truth\u0026rdquo; for your monitored files.\nUsage# lynx baseline [flags]Flags# -o, --output string: Path where the signed baseline JSON will be saved (default \u0026ldquo;baseline.json\u0026rdquo;). What it does:# Reads your config.yaml to find the target paths. Scans every file and calculates its SHA-256 hash. Signs the resulting data with your LYNX_HMAC_SECRET. Saves the results to disk. Note: You must run this whenever you intentionally change system files so the agent knows the new state is valid. 3. lynx start# Activates real-time intrusion detection.\nUsage# lynx start [flags]Flags# -b, --baseline string: Path to the verified baseline file (default \u0026ldquo;baseline.json\u0026rdquo;). What it does:# This is the main long-running process.\nLoads the baseline and verifies its HMAC signature. Initializes the inotify watcher for all configured paths. Starts the background Alert Dispatcher. Logs any file creation, modification, or deletion to the structured JSON log and sends a webhook alert if configured. 4. lynx verify# Performs a one-off manual integrity audit.\nUsage# lynx verify [flags]Flags# -b, --baseline string: Path to the verified baseline file (default \u0026ldquo;baseline.json\u0026rdquo;). What it does:# Use this for manual sweeps. It performs a full scan of the file system and compares it against the baseline immediately, printing a summary of discrepancies to the terminal. Unlike start, this command exits as soon as the audit is complete.\nüó∫Ô∏è Navigation# Installation \u0026amp; Setup: How to get the binary. Isolated Lab Testing: Safe testing tutorial. Back to Introduction "},{"id":5,"href":"/Lynx/docs/development/technical_specs/","title":"Technical Specifications","section":"Introduction","content":"Technical Architecture: The Inner Workings of Lynx FIM# This document details my technical research and the design choices I\u0026rsquo;ve made for the Lynx FIM architecture. I\u0026rsquo;m focusing on \u0026ldquo;best practice\u0026rdquo; implementations for integrity and performance as I learn the ropes of HIDS development.\n1. Core Technology: Why Go?# I\u0026rsquo;ve chosen Go (Golang) as the foundation for this project for several reasons:\nLow-Level Control with High-Level Productivity: Go gives me the performance I need for file hashing while providing a safe and productive environment for building the alerting system. Static Compilation: A single binary with no external dependencies is a massive security benefit. I don\u0026rsquo;t need to worry about the target server having the right version of Python or OpenSSL. Concurrency: Go\u0026rsquo;s goroutines will let me handle real-time file events and webhook alerting concurrently without blocking the main monitoring loop. 2. Cryptographic Strategy# To ensure data integrity, I\u0026rsquo;m using a two-layered approach:\nSHA-256 for File Hashing# I\u0026rsquo;m using the crypto/sha256 package from Go\u0026rsquo;s standard library.\nReasoning: SHA-256 is the industry standard for integrity checks. It\u0026rsquo;s collision-resistant and provides a 256-bit hash that\u0026rsquo;s perfect for identifying even a single-bit change in a multi-gigabyte file. HMAC for Baseline Protection# I\u0026rsquo;m using crypto/hmac to protect the baseline.json file.\nProblem: If an attacker modifies a system file, they might try to also modify the baseline to match the new hash. Solution: When I generate the baseline, I\u0026rsquo;ll also generate a signature of the entire file using an HMAC secret. The agent will re-calculate this signature every time it starts. Without the secret key, an attacker cannot generate a valid signature for a tampered baseline. 3. Real-Time Event Loop# I\u0026rsquo;m using the fsnotify library, which wraps the Linux inotify system call.\nHow it Works:# Watch Initialization: The agent recursively walks through the configured directories and adds an inotify watch to each one. Kernel Hook: When a file event occurs (e.g., IN_MODIFY), the kernel puts a message into a buffer for the agent. Event Handler: The agent reads from this buffer, identifies the file path, and triggers the anomaly detection logic. 4. Data Structures \u0026amp; Schemas# Configuration File (config.yaml)# agent_name: \u0026#34;dev-lab-01\u0026#34; hmac_secret_env: \u0026#34;LYNX_HMAC_SECRET\u0026#34; log_file: \u0026#34;/var/log/lynx.log\u0026#34; webhook_url: \u0026#34;https://discord.com/api/webhooks/...\u0026#34; directories_to_watch: - \u0026#34;/etc/ssh\u0026#34; - \u0026#34;/usr/local/bin\u0026#34; files_to_watch: - \u0026#34;/etc/passwd\u0026#34; - \u0026#34;/etc/hosts\u0026#34;Baseline Storage (baseline.json)# { \u0026#34;metadata\u0026#34;: { \u0026#34;generated_at\u0026#34;: \u0026#34;2025-06-20T14:00:00-04:00\u0026#34;, \u0026#34;total_files\u0026#34;: 128 }, \u0026#34;hashes\u0026#34;: { \u0026#34;/etc/passwd\u0026#34;: \u0026#34;e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\u0026#34;, \u0026#34;/etc/ssh/sshd_config\u0026#34;: \u0026#34;8b1a9953c4611296a827abf8c47804d7e6c49c6b\u0026#34; }, \u0026#34;signature\u0026#34;: \u0026#34;a94a8fe5ccb19ba61c4c0873d391e987982fbbd3\u0026#34; }5. Security Constraints# Sensitive Data: The LYNX_HMAC_SECRET must be provided as an environment variable. The agent will panic and exit if it\u0026rsquo;s not present. Privilege: The agent will need to run with sudo (root) permissions to read sensitive system files and create the inotify watches. üó∫Ô∏è Navigation# Requirements: Theoretical foundation for the HIDS. Implementation Plan: Project roadmap. Back to Introduction "},{"id":6,"href":"/Lynx/docs/development/implementation_plan/","title":"Implementation Plan","section":"Introduction","content":"Roadmap: Building Lynx FIM# This is my long-term implementation plan for Summer 2025. I\u0026rsquo;m breaking this down into three distinct phases to manage my learning and ensure each part of the system is solid before moving on.\nPhase 1: Scaffolding and Core Logic (June 2025)# The goal of Phase 1 is to build the CLI and the baseline creation logic. This is where I\u0026rsquo;ll get my first real hands-on experience with Go\u0026rsquo;s crypto libraries.\nProject Scaffolding: Set up the Go project with cobra for the CLI. Configuration System: Build a YAML-based configuration system for defining watch paths. Baseline Generation: Walk the file tree recursively. Calculate SHA-256 hashes for all files. Implement the HMAC signing logic for the baseline.json file. CLI Command - lynx init and lynx baseline: Successfully create the initial configuration and \u0026ldquo;known-good\u0026rdquo; baseline. Phase 2: Real-time Monitoring and Detection (July 2025)# The goal of Phase 2 is to move from static hashing to active monitoring. This will be my introduction to the Linux kernel\u0026rsquo;s event system.\nfsnotify Integration: Implement the core monitoring loop that listens for file events. Recursive Watching: Handle the complexity of automatically adding watches when new directories are created. Anomaly Logic: When an event occurs, compare the new file state with the memory-loaded baseline. Structured Logging: Implement JSON logging for all events (Create, Modify, Delete). CLI Command - lynx start: Begin active, real-time monitoring of the system. Phase 3: Alerting, Testing, and Hardening (August 2025)# The final phase is about making the system robust and useful in a real-world scenario.\nWebhook Integration: Build the HTTP client to send event payloads to Slack or Discord. Alert Filtering: Implement simple rules to prevent \u0026ldquo;alert fatigue\u0026rdquo; (e.g., don\u0026rsquo;t alert on temp files). Unit and Integration Testing: Write tests to ensure the hashing and HMAC logic is 100% correct. Cross-Compilation: Build and test the binary on different Linux distributions (Ubuntu, CentOS). Documentation Finalization: Complete the technical documentation and write a \u0026ldquo;getting started\u0026rdquo; guide. Beyond Summer 2025: Future Ideas# Centralized Management: Move away from local JSON logging to a central server. Automated Remediation: If a critical file is modified, automatically restore it from a secure backup. Kernel-Level Filtering: Explore more advanced ways to filter events at the kernel level for even better performance. üó∫Ô∏è Navigation# Implementation Story: Milestone-by-milestone development log. Technical Specifications: Deep dive into the architecture. Back to Introduction "},{"id":7,"href":"/Lynx/docs/usage/isolated_testing/","title":"Isolated Lab Testing (Experimental)","section":"Introduction","content":"Experimental: Isolated Lab Setup# This guide provides a step-by-step walkthrough for running a temporary, isolated Lynx FIM process. This is ideal for testing detection and alerting without modifying your system files or installing the binary globally.\nüß™ The \u0026ldquo;Single Directory\u0026rdquo; Setup# Follow these steps to create a self-contained testing environment in your /tmp directory.\n1. Prepare the Lab# # Create and enter a temporary workspace mkdir -p /tmp/lynx-lab \u0026amp;\u0026amp; cd /tmp/lynx-lab # Build the latest binary from your project root # (Assuming you are in the project root for the make command) make build cp bin/lynx /tmp/lynx-lab/ cd /tmp/lynx-lab2. Create Dummy Data to Watch# mkdir watched_dirs echo \u0026#34;secret info\u0026#34; \u0026gt; watched_dirs/top_secret.txt3. Initialize and Configure Locally# ./lynx init # Update the config to watch our lab directory instead of system paths # Also ensures the secret key is read from the correct environment variable sed -i \u0026#39;s|/etc/ssh|./watched_dirs|g\u0026#39; config.yaml sed -i \u0026#39;s|hmac_secret_env: \u0026#34;LYNX_HMAC_SECRET\u0026#34;|hmac_secret_env: \u0026#34;LYNX_HMAC_SECRET\u0026#34;|g\u0026#39; config.yaml4. Set Secret and Establish Baseline# export LYNX_HMAC_SECRET=\u0026#34;lab-secret-123\u0026#34; ./lynx baseline -o lab_baseline.json5. Start Monitoring# Run this command to start the agent. Note that this will block the current terminal window as it listens for events.\n./lynx start -b lab_baseline.jsonüîç Verifying Detection# While the process is running in Terminal 1, open a second terminal window and trigger a tampering event:\ncd /tmp/lynx-lab echo \u0026#34;tampered!\u0026#34; \u0026gt;\u0026gt; watched_dirs/top_secret.txtExpected Output (Terminal 1)# You should immediately see the alert in your first terminal: CRITICAL: File modified: /tmp/lynx-lab/watched_dirs/top_secret.txt\nüó∫Ô∏è Navigation# Installation \u0026amp; Setup: Permanent installation and service setup. Command Reference: Detailed syntax for all Lynx commands. Back to Introduction "},{"id":8,"href":"/Lynx/docs/development/implementation_story/","title":"Implementation Story","section":"Introduction","content":"The Implementation Story: A Developer\u0026rsquo;s Log# This page is where I\u0026rsquo;m documenting my notes while building Lynx FIM. It\u0026rsquo;s a record of the technical hurdles I\u0026rsquo;ve faced, the small wins, and what I\u0026rsquo;m learning as I dive into cybersecurity.\nJune 10, 2025: Getting Started# I started by laying the groundwork for the CLI. I\u0026rsquo;m using cobra because it feels like the industry standard for Go tools. Getting the project structure right was my first challenge: Go has specific conventions for cmd/ and internal/, and I want to make sure I\u0026rsquo;m following them from day one.\nI initially struggled with how to handle configuration. I want to keep the tool simple but flexible. I decided on viper for YAML support, which lets me define watch paths easily.\nJune 12, 2025: Cryptographic Wins# Today, I implemented the core integrity logic: SHA-256 hashing and HMAC signing. This is the core of any FIM agent.\nI learned that even simple things like hashing a string can be tricky. During my first unit test, I had a hash mismatch. I spent an hour debugging only to realize that my echo -n command and my Go test content had a slight difference in how they handled newlines.\nI successfully implemented HMAC-SHA256 for signing payloads. This was a big \u0026ldquo;aha!\u0026rdquo; moment for me. I now understand how a secret key can be used to prove that a file (like our baseline) hasn\u0026rsquo;t been modified by an unauthorized party.\nJune 14, 2025: Walking the File System# I\u0026rsquo;ve now implemented the \u0026ldquo;scanner\u0026rdquo; part of the agent. It recursively walks through the directories I\u0026rsquo;ve configured and gathers all the files it needs to hash.\nOne challenge I faced was handling relative paths. I want to make sure the agent is consistent, so I decided to resolve everything to absolute paths. This ensures that even if I run the agent from different directories, the \u0026ldquo;Source of Truth\u0026rdquo; remains stable.\nJune 16, 2025: Secure Baseline Storage# This was a major milestone. I\u0026rsquo;ve combined the file scanner with my cryptographic logic to create the Baseline storage system.\nI\u0026rsquo;ve implemented a system where the baseline.json file is signed with an HMAC. This means that if anyone tries to tamper with my baseline file (like changing a hash to hide their tracks), the agent will detect it immediately when it tries to load the file.\nI learned about the importance of consistent JSON marshalling. To verify the signature, I have to make sure the data I\u0026rsquo;m re-hashing is exactly the same as what I signed originally. I found that resetting the Signature field to an empty string before marshalling for verification is a clean way to handle this.\nJune 18, 2025: Learning to Trust Tests# As I move deeper into this project, I\u0026rsquo;ve decided to fully embrace Test-Driven Development (TDD). At first, it felt slow. Why write a test before the code? But as I worked on the hashing logic, I realized that in cybersecurity, \u0026ldquo;close enough\u0026rdquo; is a failure. If my integrity checks are slightly off, the whole system is useless. TDD forces me to define exactly what success looks like before I type a single line of implementation logic.\nMy workflow is now simple:\nWrite a failing test for a small piece of functionality. Write just enough code to make the test pass. Clean up the code while ensuring the test stays green. I applied this to the lynx init command today. By writing the test first, I was forced to think about the default configuration file format and ensure that even if I add new features later, the core initialization logic will still work as expected.\nJune 22, 2025: Coordinating the Baseline# Today I tied everything together with the baseline command. This was my first time coordinating multiple internal packages (crypto, fs, config) to perform a complex task.\nUsing TDD to test the coordination logic in internal/app was helpful. I could verify that the whole process (scanning files, hashing them, and saving a signed baseline) was working correctly without having to manually run the CLI every time.\nI learned about the value of mocks and environment variables in testing. To test the baseline command, I had to ensure the LYNX_HMAC_SECRET was correctly handled. Setting and unsetting environment variables in my tests made them reliable and isolated.\nJuly 1, 2025: Into the Kernel - Real-time Monitoring# Phase 1 was about the \u0026ldquo;Source of Truth\u0026rdquo; (the baseline). Phase 2 is about active defense. I\u0026rsquo;m starting to implement real-time monitoring using fsnotify.\nI\u0026rsquo;ve been reading about how the Linux kernel handles file events. Instead of my agent constantly scanning the disk, which would be slow and resource-heavy, I can use inotify (via fsnotify) to have the kernel \u0026ldquo;ping\u0026rdquo; my agent the moment a file is touched. This is a huge step up in efficiency.\nBy the end of this month, I want lynx start to be a long-running process that watches my configured paths and logs any change immediately. I\u0026rsquo;m excited but also a bit nervous about handling the complexity of recursive directory watching.\nJuly 3, 2025: Recursive Watching and Real-time Detection# I\u0026rsquo;ve successfully implemented recursive directory watching today. This was a big technical hurdle for me. When a user creates a new folder within a watched path, my agent now automatically adds that folder to its monitoring queue.\nI implemented a coordination loop that compares every file event against the memory-loaded baseline. If a file is modified, I re-hash it and compare the new signature with the old one. If it\u0026rsquo;s a new file, I log a warning. If it\u0026rsquo;s deleted, I log a critical alert.\nI learned about the importance of handling OS events correctly. For example, when a new directory is created, fsnotify gives me a Create event. I have to immediately add that directory to the watcher so I don\u0026rsquo;t miss any files created inside it a split second later.\nJuly 8, 2025: Structured Logging and the Start Command# Phase 2 is now officially complete. I\u0026rsquo;ve wired up the real-time monitor to the CLI with the new lynx start command, and I\u0026rsquo;ve implemented structured JSON logging.\nI learned that in the enterprise security world, simple text logs aren\u0026rsquo;t enough. Security Information and Event Management (SIEM) systems like Splunk or ELK need structured data. I decided to use Go\u0026rsquo;s standard library log/slog package to output all events as JSON.\nBringing everything together in cmd/start.go was satisfying. The agent now loads the configuration, verifies the signed baseline, initializes the JSON logger, and blocks while listening for file system events. It even handles termination signals (SIGINT, SIGTERM) gracefully.\nAugust 3, 2025: Real-time Alerting and Manual Audits# It is August 2025, and I\u0026rsquo;m entering the final phase of my initial learning roadmap. This month is about getting these alerts out of the log files and into a platform like Slack or Discord.\nI successfully implemented the Webhook alerting pipeline today. Using TDD, I verified that my agent can now send a structured JSON payload to any configured webhook URL. This means I can get security alerts on my phone the moment a critical system file is touched.\nI\u0026rsquo;ve also implemented the lynx verify command. This is useful for manual audits where I want to do a clean sweep and compare the entire system against the baseline without running a persistent agent.\nI learned about the power of net/http and httptest in Go. Writing tests for the webhook required me to mock a web server, which was a great exercise in understanding how HTTP requests are actually structured and sent.\nAugust 5, 2025: Speed and Security - Asynchronous Alerting# As I tested the agent, I noticed a problem: if the webhook server is slow, my whole monitoring loop blocks while it waits for a response. In a security tool, that\u0026rsquo;s unacceptable. Every millisecond of delay is a window for an attacker.\nI implemented an asynchronous AlertDispatcher today using Go\u0026rsquo;s channels and goroutines. Now, when the agent detects an anomaly, it simply \u0026ldquo;drops\u0026rdquo; the alert into a channel and gets back to monitoring immediately. A separate background process picks up the alert and handles the network delivery.\nThis was my first real experience with Go\u0026rsquo;s concurrency patterns in a production-like scenario. Learning how to use a select statement to handle both outgoing alerts and a \u0026ldquo;stop\u0026rdquo; signal was a major milestone for me. It makes the agent feel much more professional and robust.\nAugust 8, 2025: The Final Connection# Today I officially \u0026ldquo;closed the loop\u0026rdquo; by integrating the asynchronous alert dispatcher into the lynx start command.\nIt was a moment of satisfaction to see all the pieces working together. The agent now initializes the monitor, starts the background dispatcher, and then sits in a non-blocking loop waiting for file events. When an anomaly is detected, it\u0026rsquo;s logged to JSON and then immediately \u0026ldquo;fired off\u0026rdquo; to the webhook channel.\nI learned about the importance of channel buffering. By giving my channels a small buffer, I\u0026rsquo;ve made the system even more resilient to bursts of file system activity. It\u0026rsquo;s a small detail, but in a security tool, it\u0026rsquo;s the difference between catching every event and missing a critical breach.\nAugust 15, 2025: Ready for Deployment - Build Automation# As I wrap up this project, I\u0026rsquo;ve moved from writing code to thinking about how others will use it. I\u0026rsquo;ve implemented a Makefile to handle building, testing, and cross-compiling the Lynx FIM agent.\nWith one command, I can now run my entire test suite and build binaries for both amd64 and arm64 Linux servers. This is a major step toward making the agent \u0026ldquo;production-ready.\u0026rdquo; It feels like I\u0026rsquo;ve built a real tool, not just a learning project.\nI learned that automation is just as important as the code itself. By building the testing into my Makefile, I\u0026rsquo;ve ensured that I never accidentally ship a binary that hasn\u0026rsquo;t passed all my integrity checks.\nAugust 15, 2025: Final Audit and Proof of Concept# Today I performed the final end-to-end manual test of the Lynx FIM agent. I\u0026rsquo;ve vetted the codebase with go fmt and go vet, and then I ran the agent through its paces in a simulated security scenario.\nSeeing the lynx verify command catch my manual tampering with a \u0026ldquo;critical\u0026rdquo; test file was rewarding. But even better was watching the structured JSON logs populate in real-time as I modified files while the agent was running in the background.\nAugust 28, 2025: The Final Layer - CI/CD and Portability# The final piece of the puzzle was automating the build process using GitHub Actions.\nI learned that because Go binaries are statically compiled, I don\u0026rsquo;t need to target specific Linux distros like Ubuntu or CentOS. As long as I target the correct architecture (AMD64 or ARM64), the binary carries everything it needs to run.\nI successfully set up a GitHub Workflow that automatically builds and tests the agent on every push. It\u0026rsquo;s a professional touch that ensures the project is always in a \u0026ldquo;shippable\u0026rdquo; state. It\u0026rsquo;s the perfect way to conclude this 2-month intensive learning cycle.\nAugust 31, 2025: The Webhook Mystery - Discord Compatibility# I hit a major roadblock today: my webhook alerts were sending successfully from the agent, but nothing was appearing in Discord.\nI dug into the Discord Webhook documentation and realized my mistake. Discord (and Slack) don\u0026rsquo;t just display a raw JSON dump. They expect a specific field, usually content for Discord or text for Slack, to actually show a message. My original JSON payload was being ignored because it didn\u0026rsquo;t have these fields.\nI updated my Alert struct to include both content and text fields. I also updated the NewAlert function to automatically format a nice, readable summary with emojis and bold text. Now, the alerts look professional and are instantly visible in Discord.\nAugust 31, 2025: Beyond \u0026ldquo;Critical\u0026rdquo; - Dynamic Severities# As I refined the agent, I realized that labeling every single event as \u0026ldquo;CRITICAL\u0026rdquo; was creating too much noise. A new file being created in a watched directory is important (a WARNING), but a monitored configuration file being deleted or modified is an emergency (a CRITICAL event).\nI implemented a new Incident struct to replace the simple string messages I was using before. This allows the monitor to pass detailed metadata: like severity, event type, and file path, all the way up to the CLI and the webhooks.\nI ran into a tricky bug where rapid file writes were generating duplicate events in my tests. I learned the importance of \u0026ldquo;draining\u0026rdquo; channels and adding small delays to ensure my TDD assertions were reliable and focused on the right data.\nSeptember 1, 2025: Quality over Speed - Timeline Extension# I\u0026rsquo;ve decided to extend my learning roadmap into September. Originally, I thought two months would be enough, but as I got deeper into the security logic, I realized there was more to document and refine. I want to make sure I don\u0026rsquo;t saturate the project with too many rushed changes.\nThis month is about clarifying the \u0026ldquo;Security Logic\u0026rdquo; of the tool. I\u0026rsquo;ve formally documented the criteria for my CRITICAL and WARNING severity levels. This helps anyone using the tool understand exactly why they are being alerted.\nSeptember 5, 2025: Protecting the Source of Truth - Ignores and Config Integrity# As I moved into September, I focused on two critical features: a .gitignore-style mechanism for monitoring and ensuring the integrity of the configuration itself.\nI implemented ignored_patterns in the configuration. This allows users to exclude noisy files (like .tmp or .swp) while still watching the rest of a directory. But more importantly, I realized that the configuration itself is a target. If an attacker can modify the ignore list, they can hide their tracks.\nI now hash the config.yaml file and store that hash in the baseline metadata. Every time the agent starts, it re-hashes the config and compares it to the \u0026ldquo;locked\u0026rdquo; version in the baseline. If they don\u0026rsquo;t match, the agent refuses to start. It\u0026rsquo;s a \u0026ldquo;Source of Truth\u0026rdquo; for the \u0026ldquo;Source of Truth.\u0026rdquo;\nSeptember 15, 2025: Taming the Noise - Event Debouncing# As I tested the agent with real-world editors like Vim and Nano, I noticed a major issue: a single file save was triggering up to four different alerts.\nI learned that editors don\u0026rsquo;t just \u0026ldquo;write\u0026rdquo; to a file. They perform an \u0026ldquo;atomic save\u0026rdquo;: creating temporary files, deleting the original, and then renaming the new one into place. fsnotify sees every single one of these steps as a separate event.\nI implemented an event debouncer. When a file event occurs, the agent now waits for a short cooldown period (500ms). If more events arrive for that same file during the window, the timer resets. Once the activity settles, the agent only processes the final state of the file. This reduced my alert spam from 4-5 reports down to just 1 accurate FILE_MODIFIED incident.\nSystems programming requires handling the messiness of the OS. What looks like one action to a human is often a dozen rapid-fire events to the kernel.\nSeptember 20, 2025: Professional Polish - Semantic Alerting# As I reviewed the agent\u0026rsquo;s output, I realized that while emojis looked \u0026ldquo;cool\u0026rdquo; initially, they were actually bloating the logs and the webhook messages. In a high-stakes security environment, clarity is more important than aesthetics.\nI rewrote the alert formatting to use semantic labeling. Now, instead of icons, alerts are prefixed with clear, text-based indicators like [CRITICAL] or [WARNING]. This makes the data easier to parse for both humans and automated scripts.\nI also formally documented what the \u0026ldquo;Agent\u0026rdquo; field means. It\u0026rsquo;s the unique identifier for the host reporting the event. This is crucial for \u0026ldquo;Distributed Defense\u0026rdquo;: if I deploy Lynx to 50 different servers, I need to know exactly which one is being attacked based on its name.\nProfessional software should be \u0026ldquo;signal over noise.\u0026rdquo; Stripping away the fluff makes the tool feel much more serious and reliable.\nSeptember 25, 2025: Sounding the Alarm - Self-Protection Alerting# Today I realized a critical gap in my security tool: if an attacker tampered with the baseline or the configuration, the agent would log an error and exit, but it wouldn\u0026rsquo;t tell anyone why. A silent failure is an attacker\u0026rsquo;s best friend.\nI implemented self-protection alerting. Now, when the agent detects a signature mismatch or a configuration change during startup, it doesn\u0026rsquo;t just die: it sends a final, synchronous emergency alert via the webhook before shutting down. This ensures that the security team is immediately notified that the system\u0026rsquo;s \u0026ldquo;Source of Truth\u0026rdquo; has been compromised.\nA security agent must be able to defend itself. By sounding the alarm even as it fails, Lynx FIM ensures total visibility into the system\u0026rsquo;s integrity state.\nSeptember 30, 2025: Legal and Visual Closure# Today marks the final day of my three-month intensive build. I wanted to ensure the project was not only technically sound but also visually and legally complete.\nI\u0026rsquo;ve added actual screenshots of the Discord alerts to the documentation and README. Seeing the \u0026ldquo;Red\u0026rdquo; alerts in a real Discord channel is the ultimate proof that the alerting pipeline I built is robust and production-ready.\nI\u0026rsquo;ve implemented a custom license. As this project represents hundreds of hours of learning and building, I want to ensure my work is protected while still being available for others to learn from. The license mandates attribution and gives me full discretion over how the code is used or modified.\nThis project has taken me from a Go novice to building a multi-threaded, cryptographic security agent. I\u0026rsquo;m ready for whatever comes next in my cybersecurity career.\nTechnical Achievements (Project Finalized):# Verified SHA-256 hashing for files. Implemented constant-time HMAC comparison to prevent timing attacks. Established a strict test-driven development (TDD) workflow. Recursive file system traversal with absolute path resolution. HMAC-signed JSON storage for the baseline with tamper detection. CLI implementation for lynx init, lynx baseline, lynx start, and lynx verify. Core real-time monitoring with fsnotify. Recursive directory watching and anomaly detection logic. Structured JSON logging and Asynchronous Webhook alerting. Fully integrated, non-blocking alerting pipeline. Automated build system and cross-platform CI/CD. Verified Discord/Slack compatibility with visual proof. Implemented custom ownership license and final visual assets. \u0026ldquo;A project is never truly finished, it\u0026rsquo;s just ready for its next version. This journey has given me the foundation I need for a career in cybersecurity.\u0026rdquo; - Signing off on the Summer 2025 roadmap.\nüó∫Ô∏è Navigation# Proof of Concept: Seeing Lynx in action. Performance Analysis: Efficiency and scalability research. Back to Introduction "},{"id":9,"href":"/Lynx/docs/development/demonstration/","title":"Demonstration \u0026 Proof of Concept","section":"Introduction","content":"Proof of Concept: Lynx FIM in Action# This page demonstrates the Lynx FIM agent\u0026rsquo;s ability to detect and report unauthorized file system changes in real-time. Below is a correlation between the terminal commands and the resulting Discord alerts.\nüß™ Laboratory Test Scenario# In this audit, I used an isolated lab directory to verify the full lifecycle of the agent: initialization, baselining, and real-time detection.\n1. Establishing the Source of Truth# First, I generated the signed cryptographic baseline for the test directory.\nTerminal Input:\n./lynx baseline -o lab_baseline.jsonTerminal Output:\nSuccessfully created baseline: lab_baseline.json 2. Real-time Monitoring and Alerting# Next, I started the monitoring agent and triggered several file system events (modifications, deletions, and additions).\nTerminal Input:\n./lynx start -b lab_baseline.jsonLive Event Log:\n[CRITICAL] FILE_MODIFIED: ./test-dir/test2 [CRITICAL] FILE_DELETED: ./test-dir/test2.txt [WARNING] FILE_CREATED: ./test-dir/testrename.txt [WARNING] FILE_CREATED: ./test-dir/testadd3. Visual Verification (Discord)# The following image shows exactly how these events were dispatched and rendered in the Discord security channel. Note the semantic labeling and emojis used to distinguish between warnings and critical breaches.\nObservations and Lessons# Precision: The agent correctly distinguished between a file modification (CRITICAL) and a new file creation (WARNING). Responsiveness: Alerts appeared in the Discord channel within milliseconds of the file being touched in the lab. Data Integrity: The use of absolute paths in the final webhook payload ensures that the security analyst knows exactly where the event occurred on the host. üó∫Ô∏è Navigation# Performance Analysis: Efficiency and scalability research. Back to Introduction "},{"id":10,"href":"/Lynx/docs/development/performance/","title":"Performance Analysis","section":"Introduction","content":"Performance and Efficiency Research# As part of my learning journey, I wanted to understand the performance profile of Lynx FIM. Security tools must be efficient; if an agent consumes too much CPU or takes too long to hash files, it won\u0026rsquo;t be used in production.\n1. Hashing Throughput (SHA-256)# I ran benchmarks using Go\u0026rsquo;s standard crypto/sha256 library to see how fast we can process file data.\nBenchmark Results (August 2025)# File Size Time per Operation Estimated Throughput 1 MB ~0.64 ms ~1.5 GB/s 10 MB ~6.48 ms ~1.5 GB/s My Observation: Go\u0026rsquo;s implementation of SHA-256 is incredibly fast. This confirms that Lynx can handle even large configuration or binary files without significant latency.\n2. Baseline Generation Speed# I also benchmarked the coordination logic: scanning the file system, calculating hashes, and signing the output.\nResult:# 100 Files: ~1.28 ms total. My Observation: The overhead of the file system walker and the HMAC signing is negligible. For most standard server directories (like /etc/), establishing a baseline should take less than a second.\n3. Real-time Monitoring Overhead# While harder to benchmark precisely without specialized tools, my manual testing with fsnotify showed:\nCPU Usage: Near 0% while idling. Memory: Minimal (under 20MB) even when watching several hundred files. This efficiency is due to using Linux inotify hooks rather than polling the disk. It allows the agent to stay \u0026ldquo;asleep\u0026rdquo; until the kernel notifies it of an event.\n4. Complexity Analysis (Big O)# To ensure Lynx can scale to larger systems, I\u0026rsquo;ve analyzed the theoretical complexity of its core algorithms.\nPhase 1: Initial Baselining# This is the \u0026ldquo;Heavy Lifting\u0026rdquo; phase where the agent established the Source of Truth.\nTime Complexity: \\( O(N \\cdot S) \\) \\( N \\) = Number of files. \\( S \\) = Average size of the files. The agent must walk the directory tree (\\( O(N) \\)) and then read every byte of every file to calculate the SHA-256 hash (\\( O(S) \\) per file). Space Complexity: \\( O(N \\cdot P) \\) \\( P \\) = Average length of the file path string. The agent stores a map of file paths to their corresponding hashes. This map grows linearly with the number of files being monitored. Phase 2: Real-time Monitoring# This is the \u0026ldquo;Idle Defense\u0026rdquo; phase where the agent waits for events.\nTime Complexity: \\( O(S_{changed}) \\) Detection is \\( O(1) \\) because the Linux kernel pushes events to the agent (no polling required). When an event occurs, the agent only re-hashes the specific file that changed. This takes \\( O(S) \\) where \\( S \\) is the size of that modified file. Comparison with the in-memory baseline is a map lookup, which is \\( O(1) \\) on average. Space Complexity: \\( O(N \\cdot P) \\) The agent maintains the full baseline in memory to allow for instant comparisons when a file event is received. 5. Portability and Static Compilation# One of the biggest wins I discovered during this project is Go\u0026rsquo;s approach to compilation.\nTargeting Distributions vs. Architectures# I initially wondered if I needed to build separate versions for Ubuntu, CentOS, and Debian. My research taught me that because Go produces statically linked binaries (especially with CGO_ENABLED=0), the agent includes all the libraries it needs to run.\nThis means a single binary built for linux-amd64 will run on almost any modern Linux distribution without requiring any dependencies (like Python or GLIBC) to be installed on the target server.\nCI/CD Automation# I\u0026rsquo;ve implemented a GitHub Actions workflow to automate this process. Every time I push code, the system:\nRuns all unit tests to ensure no regressions. Cross-compiles the binary for both AMD64 (Standard Servers) and ARM64 (AWS Graviton / Raspberry Pi). Uploads the finished binaries as build artifacts. "}]